{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc873c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ts_outlier_detection import *\n",
    "from ts_outlier_detection.plotting import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6806047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 has 999 Fast Scattering glitches\n",
      "H1 has 100 Koi Fish glitches\n",
      "H1 has 999 Scattered Light glitches\n",
      "L1 has 999 Fast Scattering glitches\n",
      "L1 has 100 Koi Fish glitches\n",
      "L1 has 999 Scattered Light glitches\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "time_header = 'GPStime'\n",
    "fast_scattering = 'Fast Scattering'\n",
    "koi_fish = 'Koi Fish'\n",
    "scattered_light = 'Scattered Light'\n",
    "\n",
    "h1_fast_scattering_df = read_csv('data/H1_ Fast scattering - Sheet1 (1).csv')\n",
    "h1_koi_fish_df =        read_csv('data/H1_ Koi Fish - gspy (7) (2).csv')\n",
    "h1_scattered_light_df = read_csv('data/H1_ Scattered light - gspy (1).csv')\n",
    "l1_fast_scattering_df = read_csv('data/L1_ Fast-scattering - gspy (6) (1).csv')\n",
    "l1_koi_fish_df =        read_csv('data/L1_ Koi Fish - Sheet1 (1).csv')\n",
    "l1_scattered_light_df = read_csv('data/L1_ Scattered Light - gspy (1) (1).csv')\n",
    "\n",
    "H1_GLITCHES = {\n",
    "    fast_scattering: h1_fast_scattering_df[time_header].to_numpy(),\n",
    "    koi_fish:        h1_koi_fish_df[time_header].to_numpy(),\n",
    "    scattered_light: h1_scattered_light_df[time_header].to_numpy()\n",
    "}\n",
    "\n",
    "L1_GLITCHES = {\n",
    "    fast_scattering: l1_fast_scattering_df[time_header].to_numpy(),\n",
    "    koi_fish:        l1_koi_fish_df[time_header].to_numpy(),\n",
    "    scattered_light: l1_scattered_light_df[time_header].to_numpy()\n",
    "}\n",
    "\n",
    "ALL_GLITCHES = {'H1': H1_GLITCHES, 'L1': L1_GLITCHES}\n",
    "\n",
    "for det, glitches in ALL_GLITCHES.items():\n",
    "    for kind, times in glitches.items():\n",
    "        print(f'{det} has {times.size} {kind} glitches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa87eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Koi Fish events from H1\n",
      "Fetching Koi Fish events from L1\n",
      "Fetched 1 events after 4.03 seconds\n",
      "Fetched 2 events after 11.3 seconds\n",
      "Fetched 3 events after 21.21 seconds\n",
      "Fetched 4 events after 41.64 seconds\n",
      "Fetched 5 events after 51.2 seconds\n",
      "Error fetching event from H1 at 1249590821.665: HTTPSConnectionPool(host='www.gw-openscience.org', port=443): Max retries exceeded with url: /archive/links/O3a_4KHZ_R1/H1/1249590820/1249590824/json/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fab507c58b0>: Failed to establish a new connection: [Errno 11] Resource temporarily unavailable'))\n",
      "No more retries\n",
      "Fetched 6 events after 61.24 seconds\n",
      "Fetched 7 events after 71.37 seconds\n",
      "Fetched 8 events after 81.5 seconds\n",
      "Fetched 9 events after 91.26 seconds\n",
      "Fetched 10 events after 101.23 seconds\n",
      "Fetched 11 events after 111.25 seconds\n",
      "Fetched 12 events after 122.9 seconds\n",
      "Fetched 13 events after 131.74 seconds\n",
      "Fetched 14 events after 141.22 seconds\n",
      "Fetched 15 events after 151.22 seconds\n",
      "Fetched 16 events after 161.22 seconds\n",
      "Fetched 17 events after 171.24 seconds\n",
      "Fetched 18 events after 222.04 seconds\n",
      "Fetched 19 events after 252.74 seconds\n",
      "Fetched 20 events after 261.4 seconds\n",
      "Fetched 21 events after 338.63 seconds\n",
      "Fetched 22 events after 358.69 seconds\n",
      "Fetched 23 events after 400.05 seconds\n",
      "Fetched 24 events after 414.68 seconds\n",
      "Fetched 25 events after 587.03 seconds\n",
      "Fetched 26 events after 699.54 seconds\n",
      "Error fetching event from H1 at 1248748927.741: The read operation timed out\n",
      "No more retries\n",
      "Error fetching event from H1 at 1252678238.372: The read operation timed out\n",
      "No more retries\n",
      "Error fetching event from H1 at 1239022319.709: The read operation timed out\n",
      "No more retries\n",
      "Fetched 27 events after 762.41 seconds\n",
      "Error fetching event from H1 at 1238338600.932: Not enough free space in /tmp to download a 129M file, only  67M left\n",
      "No more retries\n",
      "Error fetching event from H1 at 1244153651.544: Not enough free space in /tmp to download a 129M file, only  61M left\n",
      "No more retries\n",
      "Fetched 28 events after 870.51 seconds\n",
      "Error fetching event from H1 at 1241656453.143: Not enough free space in /tmp to download a 129M file, only 1.0M left\n",
      "No more retries\n",
      "Error fetching event from H1 at 1238922082.691: [Errno 28] No space left on device\n",
      "No more retries\n",
      "Error fetching event from H1 at 1241506451.056: [Errno 28] No space left on device\n",
      "No more retries\n",
      "Error fetching event from H1 at 1241140325.998: Not enough free space in /tmp to download a 129M file, only  62M left\n",
      "No more retries\n",
      "Fetched 29 events after 888.97 seconds\n",
      "Error fetching event from H1 at 1249551299.123: Not enough free space in /tmp to download a 129M file, only  33M left\n",
      "No more retries\n",
      "Error fetching event from H1 at 1250061403.988: [Errno 28] No space left on device\n",
      "No more retries\n"
     ]
    }
   ],
   "source": [
    "## Koi Fish\n",
    "\n",
    "koi_fish_times = []\n",
    "for det, glitches in ALL_GLITCHES.items():\n",
    "    print(f'Fetching {koi_fish} events from {det}')\n",
    "    koi_fish_times.extend([(det, glitch) for glitch in glitches[koi_fish]])\n",
    "\n",
    "from random import randint\n",
    "from _thread import start_new_thread\n",
    "from time import sleep, time\n",
    "\n",
    "koi_fish_ts = []\n",
    "failed_times = []\n",
    "\n",
    "def get_koi_fish(det, gps_time, start, retries=2):\n",
    "    try:\n",
    "        koi_fish_ts.append([\n",
    "            get_processed_event(det, gps_time, length=2, bp=[(20, 300)])[0],\n",
    "            gps_time\n",
    "        ])\n",
    "        print(f'Fetched {len(koi_fish_ts)} events after {round(time()-start, 2)} seconds')\n",
    "    except Exception as e:\n",
    "        print(f'Error fetching event from {det} at {gps_time}: {e}')\n",
    "        if retries > 0:\n",
    "            print(f'Retrying {retries-1} more times')\n",
    "            sleep(randint(5, 15))\n",
    "            get_koi_fish(det, gps_time, start, retries=retries-1)\n",
    "        else:\n",
    "            print('No more retries')\n",
    "            failed_times.append(gps_time)\n",
    "\n",
    "start = time()\n",
    "for det, gps_time in koi_fish_times:\n",
    "    start_new_thread(get_koi_fish, (det, gps_time, start, 0))\n",
    "    sleep(10)\n",
    "\n",
    "training_size = 0.8\n",
    "split_idx = int(training_size*len(koi_fish_ts))\n",
    "training_set = koi_fish_ts[:split_idx]\n",
    "test_set = koi_fish_ts[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1bda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters to optimize (dims, n_neighbors, event_length)\n",
    "params = np.array([3, 4, 1024]) # initial values\n",
    "learning_rate = np.array([3, 3, 30])\n",
    "###\n",
    "\n",
    "## Gradient descent\n",
    "rng = np.random.default_rng(42)\n",
    "loss_function = diff_loss\n",
    "epochs = 3\n",
    "batch_size = 5\n",
    "max_iter = 100\n",
    "for epoch in range(epochs):\n",
    "    print(f'Starting training epoch {epoch+1}/{epochs}')\n",
    "    rng.shuffle(training_set)\n",
    "    avg_losses = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(training_set), batch_size)):\n",
    "        for _ in range(max_iter):\n",
    "            grad = np.zeros(3)\n",
    "            batch_loss = 0\n",
    "\n",
    "            for ts, actual in training_set[i:i+batch_size]:\n",
    "                data = ts.value\n",
    "                times = ts.times.value\n",
    "\n",
    "                def loss(d, n, e):\n",
    "                    ctof = TemporalOutlierfactor(dims=d, n_neighbors=n, event_length=e)\n",
    "                    ctof.fit(data, times)\n",
    "                    return loss_function(actual, times[ctof.get_outlier_indices()])\n",
    "\n",
    "                batch_loss += loss(*params)\n",
    "                grad += estimate_gradient(loss, params)\n",
    "\n",
    "            grad /= batch_size\n",
    "            avg_losses.append(batch_loss/batch_size)\n",
    "            delta = (learning_rate * grad).astype(int)\n",
    "            if np.max(np.abs(delta)) <= 0:\n",
    "                break\n",
    "            params -= delta\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "    ax.set_title(f'Epoch {epoch} losses')\n",
    "    ax.plot(np.arange(len(avg_losses)), avg_losses, 'k.')\n",
    "    ax.set_xlabel('Batch number')\n",
    "    ax.set_ylabel('Average loss over batch')\n",
    "    ax.grid(True)\n",
    "    print(f'Current optimal parameters: {params}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 with nds2",
   "language": "python",
   "name": "nds2-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
